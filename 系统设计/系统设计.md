<!-- TOC -->

- [0 参考](#0-参考)
- [1 Feed流系统](#1-feed流系统)
    - [1.1 推模式和拉模式](#11-推模式和拉模式)
    - [1.2 关注关系](#12-关注关系)
- [2 大文件问题](#2-大文件问题)
- [3 秒杀](#3-秒杀)
- [4 红包](#4-红包)
- [5 分布式ID](#5-分布式id)
- [6 定时任务](#6-定时任务)
- [7 短URL](#7-短url)
- [8 分布式限流](#8-分布式限流)
- [9 大数据问题](#9-大数据问题)
- [10 大文件排序](#10-大文件排序)

<!-- /TOC -->
# 0 参考
- [史上最全 Java 面试题](https://www.cnblogs.com/crazymakercircle/p/14367907.html)
- [advanced](https://doocs.github.io/advanced-java)
# 1 Feed流系统
[Feed流系统设计-总纲](https://developer.aliyun.com/article/706808)  
[微信朋友圈数据库模式如何设计的](https://www.zhihu.com/question/21909660)  
[如何打造千万级Feed流系统](https://developer.aliyun.com/article/224132)  

## 1.1 推模式和拉模式
- 推模式（写扩散）
    - 优点
        - 读性能高
        - 无需复杂sql查询
    - 缺点
        - 大V写入非常耗时
        - 用户关系变更需要更新队列
        - 僵尸用户的队列会占用大量存储空间
- 拉模式（读扩散）
    - 优点：
        - 实现简单
        - 用户关系变更，feed中内容动态变化，易于维护
        - 没有冗余数据，占用存储空间少
    - 缺点：
        - 查询时对feed表压力大，性能低

- 推拉结合：大部分用户的消息都是写扩散，只有大V是读扩散
- 冷热分离：用户关系在缓存里面可以设置一个过期时间，比如七天。七天没上线的可能就很少用这个 APP  
## 1.2 关注关系
[类似微博等社交软件中用户关注关系的存储实现方案遐想](https://cloud.tencent.com/developer/article/1451238)
- 分库分表：以 fromuid 为 hash key 存一份，以 touid 为 hash key 再存一份
- Redis：[微博关系服务与 Redis 的故事](https://www.infoq.cn/article/weibo-relation-service-with-redis)

# 2 大文件问题


# 3 秒杀
- 请求尽量拦截在系统上游
    - CDN缓存静态页面
    - 前端禁止用户重复提交请求
    - 后端针对id限制访问次数
    - 限流
    - 请求排队
- 控制超卖
    - lua脚本
    - redis list/decr：只能扣一个
# 4 红包
- 垂直切分：根据红包ID，发红包、抢红包、拆红包、查详情等等都在同一台机器上处理，互不影响
- 请求进行排队
# 5 分布式ID
- mysql
- redis
- snowflake
# 6 定时任务 
任务轮询或任务轮询+抢占排队方案
- 每个服务器首次启动时加入队列；
- 每次任务运行首先判断自己是否是当前可运行任务，如果是便运行；
- 如果不是当前运行的任务，检查自己是否在队列中，如果在，便退出，如果不在队列中，进入队列。

# 7 短URL
[系统设计系列之如何设计一个短链服务](https://xie.infoq.cn/article/483fcfbe3f942cb1fa9d9ce20)
1. 分布式ID生成器产生ID
2. ID转62进制字符串
3. 记录数据库，根据业务要求确定过期时间，可以保留部分永久链接
# 8 分布式限流
Redis+Lua 脚本实现令牌桶

# 9 大数据问题
包括找相同URL，找高频词，统计最多IP
- 通过hash分为小文件
- 用堆
    - 求解最大的 TopN 个，用小顶堆；
    - 求解最小的 TopN 个，用大顶堆。
# 10 大文件排序
[面试题热个身：5 亿整数的大文件，来排个序？](https://cloud.tencent.com/developer/article/1592913)
- 外归并排序按如下方法操作：
    1. 读入100 MB的数据至内存中，用某种常规方式（如快速排序、堆排序、归并排序等方法）在内存中完成排序。
    2. 将排序完成的数据写入磁盘。
    3. 重复步骤1和2直到所有的数据都存入了不同的100 MB的块（临时文件）中。在这个例子中，有900 MB数据，单个临时文件大小为100 MB，所以会产生9个临时文件。
    4. 读入每个临时文件（顺串）的前10 MB（ = 100 MB / (9块 + 1)）的数据放入内存中的输入缓冲区，最后的10 MB作为输出缓冲区。（实践中，将输入缓冲适当调小，而适当增大输出缓冲区能获得更好的效果。）
    5. 执行九路归并算法，将结果输出到输出缓冲区。一旦输出缓冲区满，将缓冲区中的数据写出至目标文件，清空缓冲区。一旦9个输入缓冲区中的一个变空，就从这个缓冲区关联的文件，读入下一个10M数据，除非这个文件已读完。
    - [486 · 合并k个排序数组](https://www.lintcode.com/problem/486/)
- 位图法
1MB=1024*1024*8 个数
